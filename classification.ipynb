{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:15:05.596821Z",
     "start_time": "2024-07-12T05:14:58.538822Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, Sequential, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from generator import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def plot():\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss', marker=\".\")\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [MPG]')\n",
    "    plot()\n",
    "\n",
    "def pre_process_isotherm(isotherm):\n",
    "    #isotherm -= min(isotherm)\n",
    "    isotherm /= max(isotherm)\n",
    "    return isotherm\n",
    "    \n",
    "def load_dataset(path, interp=False, gen_silica=None, gen_carbon=None):\n",
    "    min_exp_pressure_i = 40\n",
    "    max_exp_pressure_i = 458\n",
    "    with open(path, 'rb') as f:\n",
    "            dataset = np.load(f)\n",
    "            isotherm_data = dataset[\"isotherm_data\"]\n",
    "            pore_distribution_data = dataset[\"pore_distribution_data\"]\n",
    "    x = np.empty((isotherm_data.shape[0], (-min_exp_pressure_i + max_exp_pressure_i)))\n",
    "    y = np.empty(pore_distribution_data.shape)\n",
    "    for i in range(len(isotherm_data)):\n",
    "        if interp:\n",
    "            interp_isotherm = np.interp(gen_silica.pressures_s, gen_carbon.pressures_s, isotherm_data[i])\n",
    "        else:\n",
    "            interp_isotherm = isotherm_data[i]\n",
    "        isotherm = pre_process_isotherm(interp_isotherm[min_exp_pressure_i:max_exp_pressure_i])\n",
    "        pore_distribution = pre_process_isotherm(pore_distribution_data[i])\n",
    "        x[i] = isotherm\n",
    "        y[i] = pore_distribution\n",
    "    #x, y = shuffle(x, y)\n",
    "    return x, y\n",
    "\n",
    "def create_model(input_shape):\n",
    "    ## CONV NET\n",
    "    # model = Sequential()\n",
    "    # model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(input_shape,1)))\n",
    "    # model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    # model.add(layers.Dropout(0.5))\n",
    "    # model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    # model.add(layers.Flatten())\n",
    "    # model.add(layers.Dense(100, activation='relu'))\n",
    "    # model.add(layers.Dense(2, activation='softmax'))\n",
    "    ###\n",
    "        ## DENSE NET\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Input(shape=len(x_train[0],)),\n",
    "            layers.Dense(400, activation='relu'),\n",
    "            layers.Dense(200, activation='relu'),\n",
    "            layers.Dense(100, activation='relu'),\n",
    "            layers.Dense(50, activation='relu'),\n",
    "            layers.Dense(2, activation='softmax')\n",
    "        ]\n",
    "    )\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:15:14.750848Z",
     "start_time": "2024-07-12T05:15:14.734846Z"
    }
   },
   "id": "586d532d7b2b798d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "gen_silica = Generator(path_s=\"data/kernel_generated2/Kernel_s_Silica-loc-isoth1.xlsx.npy\",\n",
    "                              path_d=\"data/kernel_generated2/Kernel_d_Silica-loc-isoth1.xlsx.npy\",\n",
    "                              path_p_d=\"data/kernel_generated2/Pressure_d_Silica-loc-isoth1.xlsx.npy\",\n",
    "                              path_p_s=\"data/kernel_generated2/Pressure_s_Silica-loc-isoth1.xlsx.npy\",\n",
    "                              path_a=\"data/kernel_generated2/Size_Silica-loc-isoth1.xlsx.npy\"\n",
    "                              )\n",
    "gen_carbon = Generator(path_s=\"data/initial kernels/Kernel_Carbon_Adsorption.npy\",\n",
    "                              path_d=\"data/initial kernels/Kernel_Carbon_Desorption.npy\",\n",
    "                              path_p_d=\"data/initial kernels/Pressure_Carbon.npy\",\n",
    "                              path_p_s=\"data/initial kernels/Pressure_Carbon.npy\",\n",
    "                              path_a=\"data/initial kernels/Size_Kernel_Carbon_Adsorption.npy\"\n",
    "                              )\n",
    "x1, y1 = load_dataset('data/datasets/carbon_random_classification.npz', interp=True, gen_carbon=gen_carbon, gen_silica=gen_silica)\n",
    "x2, y2 = load_dataset('data/datasets/silica_random_classification.npz', interp=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:15:59.333923Z",
     "start_time": "2024-07-12T05:15:55.402823Z"
    }
   },
   "id": "52a4935677a58471"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "i = random.randint(0, len(x1))\n",
    "plt.plot(x1[i], marker=\".\", label=\"Carbon isotherm\")\n",
    "plt.plot(x2[i], marker=\".\", label=\"Silica isotherm\")\n",
    "# plt.plot(gen_carbon.a_array, y1[i], marker=\".\", label=\"Carbon distribution\")\n",
    "# plt.plot(gen_silica.a_array, y2[i], marker=\".\", label=\"Silica distribution\")\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:16:07.183823Z",
     "start_time": "2024-07-12T05:16:02.360849Z"
    }
   },
   "id": "9e18e14b8cfdd6a7"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "y_carbon = np.empty(shape = (len(x1), 2))\n",
    "y_silica = np.empty(shape = (len(x1), 2))\n",
    "y = np.empty(shape = (len(x1), 2))\n",
    "x = np.empty(shape = x1.shape)\n",
    "for i in range(len(x1)):\n",
    "    a = random.random()\n",
    "    y[i] = np.array([a, 1-a])\n",
    "    x[i] = x1[i]*a + x2[i]*(1-a)\n",
    "    # y_carbon[i] = np.array([0, 1])\n",
    "    # y_silica[i] = np.array([1, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:25:09.416826Z",
     "start_time": "2024-07-12T05:25:09.194854Z"
    }
   },
   "id": "63cc2fed24fea18c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "x = np.concatenate((x1, x2), axis=0)\n",
    "y = np.concatenate((y_carbon, y_silica), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:16:10.888922Z",
     "start_time": "2024-07-12T05:16:10.827849Z"
    }
   },
   "id": "e89a163621b67952"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:25:12.226858Z",
     "start_time": "2024-07-12T05:25:12.178848Z"
    }
   },
   "id": "f7e19ca9ee63cd00"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "model = create_model(input_shape=len(x[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:25:14.106922Z",
     "start_time": "2024-07-12T05:25:14.043824Z"
    }
   },
   "id": "485d210c2dda2d6e"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.7102 - accuracy: 0.5814\n",
      "Epoch 1: accuracy improved from -inf to 0.66991, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6574 - accuracy: 0.6699 - val_loss: 0.6541 - val_accuracy: 0.6552 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6522 - accuracy: 0.6606\n",
      "Epoch 2: accuracy improved from 0.66991 to 0.68644, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.6431 - accuracy: 0.6864 - val_loss: 0.6360 - val_accuracy: 0.6977 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6370 - accuracy: 0.6964\n",
      "Epoch 3: accuracy improved from 0.68644 to 0.73733, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6253 - accuracy: 0.7373 - val_loss: 0.6086 - val_accuracy: 0.7981 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6069 - accuracy: 0.7856\n",
      "Epoch 4: accuracy improved from 0.73733 to 0.76427, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6125 - accuracy: 0.7643 - val_loss: 0.6139 - val_accuracy: 0.7661 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6156 - accuracy: 0.7610\n",
      "Epoch 5: accuracy improved from 0.76427 to 0.79564, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6021 - accuracy: 0.7956 - val_loss: 0.5907 - val_accuracy: 0.8412 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5881 - accuracy: 0.8318\n",
      "Epoch 6: accuracy improved from 0.79564 to 0.81493, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5935 - accuracy: 0.8149 - val_loss: 0.5973 - val_accuracy: 0.8021 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5960 - accuracy: 0.8014\n",
      "Epoch 7: accuracy improved from 0.81493 to 0.82484, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5899 - accuracy: 0.8248 - val_loss: 0.6007 - val_accuracy: 0.7924 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5955 - accuracy: 0.7986\n",
      "Epoch 8: accuracy did not improve from 0.82484\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5893 - accuracy: 0.8196 - val_loss: 0.5827 - val_accuracy: 0.8472 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5789 - accuracy: 0.8448\n",
      "Epoch 9: accuracy improved from 0.82484 to 0.83440, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5833 - accuracy: 0.8344 - val_loss: 0.5791 - val_accuracy: 0.8567 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5766 - accuracy: 0.8576\n",
      "Epoch 10: accuracy did not improve from 0.83440\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5841 - accuracy: 0.8298 - val_loss: 0.5947 - val_accuracy: 0.8103 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5896 - accuracy: 0.8090\n",
      "Epoch 11: accuracy did not improve from 0.83440\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5839 - accuracy: 0.8306 - val_loss: 0.5824 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5774 - accuracy: 0.8388\n",
      "Epoch 12: accuracy did not improve from 0.83440\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5873 - accuracy: 0.8198 - val_loss: 0.5836 - val_accuracy: 0.8293 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5841 - accuracy: 0.8356\n",
      "Epoch 13: accuracy improved from 0.83440 to 0.85040, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5758 - accuracy: 0.8504 - val_loss: 0.5842 - val_accuracy: 0.8259 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5821 - accuracy: 0.8316\n",
      "Epoch 14: accuracy did not improve from 0.85040\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5933 - accuracy: 0.8006 - val_loss: 0.5835 - val_accuracy: 0.8401 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5793 - accuracy: 0.8294\n",
      "Epoch 15: accuracy did not improve from 0.85040\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5775 - accuracy: 0.8430 - val_loss: 0.6010 - val_accuracy: 0.7909 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5914 - accuracy: 0.7906\n",
      "Epoch 16: accuracy did not improve from 0.85040\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5937 - accuracy: 0.7976 - val_loss: 0.5798 - val_accuracy: 0.8489 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5779 - accuracy: 0.8484\n",
      "Epoch 17: accuracy did not improve from 0.85040\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5883 - accuracy: 0.8131 - val_loss: 0.5747 - val_accuracy: 0.8569 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5706 - accuracy: 0.8598\n",
      "Epoch 18: accuracy did not improve from 0.85040\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5782 - accuracy: 0.8443 - val_loss: 0.5970 - val_accuracy: 0.7917 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5956 - accuracy: 0.8070\n",
      "Epoch 19: accuracy did not improve from 0.85040\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5785 - accuracy: 0.8410 - val_loss: 0.5851 - val_accuracy: 0.8216 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5838 - accuracy: 0.8294\n",
      "Epoch 20: accuracy did not improve from 0.85040\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5970 - accuracy: 0.7938 - val_loss: 0.5773 - val_accuracy: 0.8543 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5753 - accuracy: 0.8522\n",
      "Epoch 21: accuracy did not improve from 0.85040\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5836 - accuracy: 0.8265 - val_loss: 0.5959 - val_accuracy: 0.7983 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5914 - accuracy: 0.8010\n",
      "Epoch 22: accuracy did not improve from 0.85040\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5788 - accuracy: 0.8383 - val_loss: 0.5859 - val_accuracy: 0.8276 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5824 - accuracy: 0.8240\n",
      "Epoch 23: accuracy did not improve from 0.85040\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5772 - accuracy: 0.8406 - val_loss: 0.5743 - val_accuracy: 0.8535 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5670 - accuracy: 0.8646\n",
      "Epoch 24: accuracy improved from 0.85040 to 0.85556, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5720 - accuracy: 0.8556 - val_loss: 0.5901 - val_accuracy: 0.8148 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5911 - accuracy: 0.8072\n",
      "Epoch 25: accuracy did not improve from 0.85556\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6010 - accuracy: 0.7813 - val_loss: 0.5714 - val_accuracy: 0.8647 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5683 - accuracy: 0.8682\n",
      "Epoch 26: accuracy did not improve from 0.85556\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5982 - accuracy: 0.7935 - val_loss: 0.5772 - val_accuracy: 0.8501 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5726 - accuracy: 0.8472\n",
      "Epoch 27: accuracy did not improve from 0.85556\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5868 - accuracy: 0.8166 - val_loss: 0.5862 - val_accuracy: 0.8243 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5783 - accuracy: 0.8260\n",
      "Epoch 28: accuracy did not improve from 0.85556\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5818 - accuracy: 0.8266 - val_loss: 0.5896 - val_accuracy: 0.8116 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5840 - accuracy: 0.8130\n",
      "Epoch 29: accuracy did not improve from 0.85556\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5791 - accuracy: 0.8331 - val_loss: 0.5884 - val_accuracy: 0.8160 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5856 - accuracy: 0.8122\n",
      "Epoch 30: accuracy did not improve from 0.85556\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5797 - accuracy: 0.8320 - val_loss: 0.5776 - val_accuracy: 0.8460 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5769 - accuracy: 0.8460\n",
      "Epoch 31: accuracy did not improve from 0.85556\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5870 - accuracy: 0.8118 - val_loss: 0.5696 - val_accuracy: 0.8680 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5685 - accuracy: 0.8772\n",
      "Epoch 32: accuracy did not improve from 0.85556\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5811 - accuracy: 0.8278 - val_loss: 0.5842 - val_accuracy: 0.8205 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5778 - accuracy: 0.8288\n",
      "Epoch 33: accuracy did not improve from 0.85556\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5712 - accuracy: 0.8528 - val_loss: 0.5766 - val_accuracy: 0.8429 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5719 - accuracy: 0.8522\n",
      "Epoch 34: accuracy did not improve from 0.85556\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5805 - accuracy: 0.8290 - val_loss: 0.5777 - val_accuracy: 0.8463 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5724 - accuracy: 0.8438\n",
      "Epoch 35: accuracy improved from 0.85556 to 0.85778, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5693 - accuracy: 0.8578 - val_loss: 0.6066 - val_accuracy: 0.7707 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6048 - accuracy: 0.7698\n",
      "Epoch 36: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5990 - accuracy: 0.7897 - val_loss: 0.5887 - val_accuracy: 0.8159 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5845 - accuracy: 0.8156\n",
      "Epoch 37: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5814 - accuracy: 0.8263 - val_loss: 0.5764 - val_accuracy: 0.8444 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5720 - accuracy: 0.8418\n",
      "Epoch 38: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5722 - accuracy: 0.8500 - val_loss: 0.5676 - val_accuracy: 0.8729 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5642 - accuracy: 0.8738\n",
      "Epoch 39: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5754 - accuracy: 0.8390 - val_loss: 0.6022 - val_accuracy: 0.7737 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5964 - accuracy: 0.7808\n",
      "Epoch 40: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5787 - accuracy: 0.8326 - val_loss: 0.5699 - val_accuracy: 0.8589 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5711 - accuracy: 0.8570\n",
      "Epoch 41: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5958 - accuracy: 0.7947 - val_loss: 0.5759 - val_accuracy: 0.8536 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5704 - accuracy: 0.8628\n",
      "Epoch 42: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5871 - accuracy: 0.8176 - val_loss: 0.5832 - val_accuracy: 0.8213 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5839 - accuracy: 0.8254\n",
      "Epoch 43: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5829 - accuracy: 0.8215 - val_loss: 0.5833 - val_accuracy: 0.8267 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5820 - accuracy: 0.8254\n",
      "Epoch 44: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5731 - accuracy: 0.8465 - val_loss: 0.5783 - val_accuracy: 0.8365 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5764 - accuracy: 0.8424\n",
      "Epoch 45: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5734 - accuracy: 0.8435 - val_loss: 0.5673 - val_accuracy: 0.8691 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5617 - accuracy: 0.8712\n",
      "Epoch 46: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5774 - accuracy: 0.8353 - val_loss: 0.5786 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5731 - accuracy: 0.8426\n",
      "Epoch 47: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5697 - accuracy: 0.8522 - val_loss: 0.5941 - val_accuracy: 0.8005 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5865 - accuracy: 0.8056\n",
      "Epoch 48: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5856 - accuracy: 0.8118 - val_loss: 0.5643 - val_accuracy: 0.8785 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5618 - accuracy: 0.8716\n",
      "Epoch 49: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5703 - accuracy: 0.8477 - val_loss: 0.5820 - val_accuracy: 0.8200 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5827 - accuracy: 0.8242\n",
      "Epoch 50: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5689 - accuracy: 0.8553 - val_loss: 0.5684 - val_accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5649 - accuracy: 0.8682\n",
      "Epoch 51: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5840 - accuracy: 0.8204 - val_loss: 0.5807 - val_accuracy: 0.8352 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5809 - accuracy: 0.8192\n",
      "Epoch 52: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5788 - accuracy: 0.8287 - val_loss: 0.5862 - val_accuracy: 0.8161 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5808 - accuracy: 0.8140\n",
      "Epoch 53: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5719 - accuracy: 0.8444 - val_loss: 0.5847 - val_accuracy: 0.8204 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5826 - accuracy: 0.8234\n",
      "Epoch 54: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5695 - accuracy: 0.8514 - val_loss: 0.5905 - val_accuracy: 0.8032 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5863 - accuracy: 0.7994\n",
      "Epoch 55: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5773 - accuracy: 0.8291 - val_loss: 0.5740 - val_accuracy: 0.8504 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5702 - accuracy: 0.8444\n",
      "Epoch 56: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5735 - accuracy: 0.8381 - val_loss: 0.5721 - val_accuracy: 0.8467 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5690 - accuracy: 0.8536\n",
      "Epoch 57: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5671 - accuracy: 0.8552 - val_loss: 0.5814 - val_accuracy: 0.8291 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5793 - accuracy: 0.8258\n",
      "Epoch 58: accuracy did not improve from 0.85778\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5803 - accuracy: 0.8224 - val_loss: 0.5672 - val_accuracy: 0.8613 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5604 - accuracy: 0.8722\n",
      "Epoch 59: accuracy improved from 0.85778 to 0.86342, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5641 - accuracy: 0.8634 - val_loss: 0.5690 - val_accuracy: 0.8607 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5619 - accuracy: 0.8626\n",
      "Epoch 60: accuracy did not improve from 0.86342\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5633 - accuracy: 0.8631 - val_loss: 0.5669 - val_accuracy: 0.8581 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5663 - accuracy: 0.8566\n",
      "Epoch 61: accuracy did not improve from 0.86342\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5810 - accuracy: 0.8198 - val_loss: 0.5975 - val_accuracy: 0.7968 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5924 - accuracy: 0.7958\n",
      "Epoch 62: accuracy did not improve from 0.86342\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5720 - accuracy: 0.8443 - val_loss: 0.5808 - val_accuracy: 0.8288 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5764 - accuracy: 0.8234\n",
      "Epoch 63: accuracy did not improve from 0.86342\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5861 - accuracy: 0.8081 - val_loss: 0.5679 - val_accuracy: 0.8652 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5640 - accuracy: 0.8606\n",
      "Epoch 64: accuracy did not improve from 0.86342\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5740 - accuracy: 0.8357 - val_loss: 0.5649 - val_accuracy: 0.8717 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5614 - accuracy: 0.8648\n",
      "Epoch 65: accuracy did not improve from 0.86342\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5723 - accuracy: 0.8378 - val_loss: 0.5607 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5614 - accuracy: 0.8830\n",
      "Epoch 66: accuracy did not improve from 0.86342\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5710 - accuracy: 0.8459 - val_loss: 0.5773 - val_accuracy: 0.8296 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5750 - accuracy: 0.8308\n",
      "Epoch 67: accuracy did not improve from 0.86342\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5638 - accuracy: 0.8604 - val_loss: 0.5913 - val_accuracy: 0.7951 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5877 - accuracy: 0.8076\n",
      "Epoch 68: accuracy did not improve from 0.86342\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5794 - accuracy: 0.8216 - val_loss: 0.5603 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5582 - accuracy: 0.8838\n",
      "Epoch 69: accuracy improved from 0.86342 to 0.87596, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5582 - accuracy: 0.8760 - val_loss: 0.5783 - val_accuracy: 0.8332 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5752 - accuracy: 0.8358\n",
      "Epoch 70: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5743 - accuracy: 0.8365 - val_loss: 0.5615 - val_accuracy: 0.8803 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5602 - accuracy: 0.8676\n",
      "Epoch 71: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5830 - accuracy: 0.8191 - val_loss: 0.5742 - val_accuracy: 0.8377 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5684 - accuracy: 0.8404\n",
      "Epoch 72: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5623 - accuracy: 0.8637 - val_loss: 0.5716 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5716 - accuracy: 0.8336\n",
      "Epoch 73: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5688 - accuracy: 0.8424 - val_loss: 0.5617 - val_accuracy: 0.8796 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5586 - accuracy: 0.8724\n",
      "Epoch 74: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5654 - accuracy: 0.8560 - val_loss: 0.6120 - val_accuracy: 0.7635 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6063 - accuracy: 0.7754\n",
      "Epoch 75: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5860 - accuracy: 0.8156 - val_loss: 0.5977 - val_accuracy: 0.7889 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5930 - accuracy: 0.7942\n",
      "Epoch 76: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5742 - accuracy: 0.8345 - val_loss: 0.5849 - val_accuracy: 0.8163 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5776 - accuracy: 0.8190\n",
      "Epoch 77: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5701 - accuracy: 0.8437 - val_loss: 0.5883 - val_accuracy: 0.8069 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5834 - accuracy: 0.8120\n",
      "Epoch 78: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5690 - accuracy: 0.8456 - val_loss: 0.5760 - val_accuracy: 0.8384 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5689 - accuracy: 0.8468\n",
      "Epoch 79: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5642 - accuracy: 0.8579 - val_loss: 0.5834 - val_accuracy: 0.8204 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5789 - accuracy: 0.8224\n",
      "Epoch 80: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5670 - accuracy: 0.8507 - val_loss: 0.5681 - val_accuracy: 0.8568 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5624 - accuracy: 0.8562\n",
      "Epoch 81: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5644 - accuracy: 0.8548 - val_loss: 0.5618 - val_accuracy: 0.8687 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5587 - accuracy: 0.8678\n",
      "Epoch 82: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5578 - accuracy: 0.8721 - val_loss: 0.5651 - val_accuracy: 0.8659 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5619 - accuracy: 0.8678\n",
      "Epoch 83: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5805 - accuracy: 0.8186 - val_loss: 0.5749 - val_accuracy: 0.8313 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5702 - accuracy: 0.8312\n",
      "Epoch 84: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5687 - accuracy: 0.8441 - val_loss: 0.6364 - val_accuracy: 0.7099 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6300 - accuracy: 0.7192\n",
      "Epoch 85: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5854 - accuracy: 0.8076 - val_loss: 0.5633 - val_accuracy: 0.8647 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5558 - accuracy: 0.8768\n",
      "Epoch 86: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5676 - accuracy: 0.8483 - val_loss: 0.5564 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5522 - accuracy: 0.8888\n",
      "Epoch 87: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5628 - accuracy: 0.8597 - val_loss: 0.5563 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5519 - accuracy: 0.8874\n",
      "Epoch 88: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5626 - accuracy: 0.8598 - val_loss: 0.5565 - val_accuracy: 0.8843 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5541 - accuracy: 0.8772\n",
      "Epoch 89: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5605 - accuracy: 0.8644 - val_loss: 0.5968 - val_accuracy: 0.7784 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5999 - accuracy: 0.7836\n",
      "Epoch 90: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5683 - accuracy: 0.8464 - val_loss: 0.5812 - val_accuracy: 0.8105 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5792 - accuracy: 0.8136\n",
      "Epoch 91: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5738 - accuracy: 0.8324 - val_loss: 0.5658 - val_accuracy: 0.8547 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5612 - accuracy: 0.8550\n",
      "Epoch 92: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5739 - accuracy: 0.8310 - val_loss: 0.5544 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5503 - accuracy: 0.8948\n",
      "Epoch 93: accuracy did not improve from 0.87596\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5621 - accuracy: 0.8569 - val_loss: 0.5599 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5579 - accuracy: 0.8654\n",
      "Epoch 94: accuracy improved from 0.87596 to 0.88049, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5532 - accuracy: 0.8805 - val_loss: 0.5742 - val_accuracy: 0.8421 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5692 - accuracy: 0.8396\n",
      "Epoch 95: accuracy did not improve from 0.88049\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5688 - accuracy: 0.8400 - val_loss: 0.5537 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5492 - accuracy: 0.8846\n",
      "Epoch 96: accuracy improved from 0.88049 to 0.88911, saving model to data/models\\classification.keras\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5491 - accuracy: 0.8891 - val_loss: 0.5531 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5514 - accuracy: 0.8882\n",
      "Epoch 97: accuracy did not improve from 0.88911\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5561 - accuracy: 0.8708 - val_loss: 0.6361 - val_accuracy: 0.7137 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6322 - accuracy: 0.7330\n",
      "Epoch 98: accuracy did not improve from 0.88911\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5891 - accuracy: 0.8092 - val_loss: 0.5632 - val_accuracy: 0.8593 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5589 - accuracy: 0.8616\n",
      "Epoch 99: accuracy did not improve from 0.88911\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5809 - accuracy: 0.8188 - val_loss: 0.5592 - val_accuracy: 0.8763 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5543 - accuracy: 0.8762\n",
      "Epoch 100: accuracy did not improve from 0.88911\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5655 - accuracy: 0.8504 - val_loss: 0.5533 - val_accuracy: 0.8928 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "mcp_save = tf.keras.callbacks.ModelCheckpoint(filepath='data/models/classification.keras', save_best_only=True,\n",
    "                                           monitor='accuracy', mode='max', verbose=1, save_weights_only=False,\n",
    "                                           save_freq='epoch')\n",
    "\n",
    "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                                   patience=100, verbose=1, mode='auto')\n",
    "history = model.fit(np.array(x_train), np.array(y_train),\n",
    "                    epochs=100, batch_size=5000, shuffle=True,\n",
    "                    validation_data=(np.array(x_test), np.array(y_test)), callbacks=[mcp_save, reduce_lr_loss])\n",
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:26:06.172822Z",
     "start_time": "2024-07-12T05:25:40.140821Z"
    }
   },
   "id": "f3eb22e74bff9cd0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('data/models/classification.keras')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:27:50.205821Z",
     "start_time": "2024-07-12T05:27:49.985823Z"
    }
   },
   "id": "2de0973232aa8352",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(np.array(x_train))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:27:52.459922Z",
     "start_time": "2024-07-12T05:27:50.803857Z"
    }
   },
   "id": "772a99fc641a54cf",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0.25203574, 0.7479642 ], dtype=float32),\n array([0.25625809, 0.74374191]))"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 1231\n",
    "prediction[j], y_train[j]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:28:22.443824Z",
     "start_time": "2024-07-12T05:28:22.427847Z"
    }
   },
   "id": "648cf4566446c7bb",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gen = Generator(path_s=\"data/initial kernels/Kernel_Silica_Adsorption.npy\",\n",
    "                path_d=\"data/initial kernels/Kernel_Silica_Desorption.npy\",\n",
    "                path_p_d=\"data/initial kernels/Pressure_Silica.npy\",\n",
    "                path_p_s=\"data/initial kernels/Pressure_Silica.npy\",\n",
    "                path_a=\"data/initial kernels/Size_Kernel_Silica_Adsorption.npy\"\n",
    "                )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:31:58.589824Z",
     "start_time": "2024-07-12T05:31:58.574824Z"
    }
   },
   "id": "54a708650207262",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "exp_file_list = [\"MCM-41\", \"SBA-15\", \"SBA-16\", \"MIL-101\", \"MIL-101_2\", \"DUT-49\", \"FDM-4\", \"PCN-333\", \"PCN-777\",\n",
    "                 \"MIL-100\"]\n",
    "\n",
    "p_exp_list = []\n",
    "n_s_exp_raw_list = []\n",
    "for exp_file_name in exp_file_list:\n",
    "    data = pd.read_csv(f\"data/real/{exp_file_name}.txt\", header=None)\n",
    "    # p_exp_list.append(data.iloc[:,1].to_numpy())\n",
    "    # n_s_exp_raw_list.append(data.iloc[:,3].to_numpy())\n",
    "    p_exp_list.append(data.iloc[:, 1].to_numpy())\n",
    "    n_s_exp_raw_list.append(data.iloc[:, 3].to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:32:00.635927Z",
     "start_time": "2024-07-12T05:32:00.604824Z"
    }
   },
   "id": "f74420bb0c7dd326"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "j = 2\n",
    "plt.plot(p_exp_list[j], n_s_exp_raw_list[j], marker=\".\", label=exp_file_list[j])\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:32:02.314824Z",
     "start_time": "2024-07-12T05:32:01.237823Z"
    }
   },
   "id": "571a14d6fe31a7fc",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# интерполируем экспериментальную изотерму под давления кернала\n",
    "n_s_exp_list = []\n",
    "for i in range(len(p_exp_list)):\n",
    "    n_s_exp_list.append(np.interp(gen.pressures_s[40:458], p_exp_list[i], n_s_exp_raw_list[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:32:02.921824Z",
     "start_time": "2024-07-12T05:32:02.906821Z"
    }
   },
   "id": "630dacdf89beb67c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "j = 2\n",
    "plt.plot(gen.pressures_s[40:458], n_s_exp_list[j], marker=\".\", label=exp_file_list[j])\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:32:05.144824Z",
     "start_time": "2024-07-12T05:32:03.724821Z"
    }
   },
   "id": "37c7bc6cc3c50cdf",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "n_s_exp_for_net_list = [pre_process_isotherm(n_s_exp) for n_s_exp in n_s_exp_list]\n",
    "fit_exp_list = [model.predict(np.array([n_s_exp_for_net])).T for n_s_exp_for_net in n_s_exp_for_net_list]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:32:06.652825Z",
     "start_time": "2024-07-12T05:32:06.102824Z"
    }
   },
   "id": "9d9bba6cd5b05a67"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCM-41 carbon [[0.8763423 ]\n",
      " [0.12365764]]\n",
      "SBA-15 silica [[0.29072034]\n",
      " [0.70927966]]\n",
      "SBA-16 carbon [[0.75448936]\n",
      " [0.24551064]]\n",
      "MIL-101 carbon [[0.5979614]\n",
      " [0.4020386]]\n",
      "MIL-101_2 silica [[0.01152014]\n",
      " [0.9884799 ]]\n",
      "DUT-49 carbon [[0.8140122 ]\n",
      " [0.18598773]]\n",
      "FDM-4 silica [[0.02563336]\n",
      " [0.97436666]]\n",
      "PCN-333 carbon [[0.7265499 ]\n",
      " [0.27345008]]\n",
      "PCN-777 carbon [[0.7881956 ]\n",
      " [0.21180442]]\n",
      "MIL-100 carbon [[0.6727861]\n",
      " [0.3272139]]\n"
     ]
    }
   ],
   "source": [
    "for i, prediction in enumerate(fit_exp_list):\n",
    "    if np.argmax(prediction) == 1:\n",
    "        print(exp_file_list[i], \"silica\", prediction)\n",
    "    else:\n",
    "        print(exp_file_list[i], \"carbon\", prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T05:34:24.736822Z",
     "start_time": "2024-07-12T05:34:24.720824Z"
    }
   },
   "id": "beb2bc6b1a61f235"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-17T15:19:12.318470Z"
    }
   },
   "id": "554088104cad624e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
