{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.layers import Dense,LSTM, Concatenate, Input, Conv1D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling1D, MaxPooling1D, GlobalAveragePooling1D, UpSampling1D, concatenate, Conv1DTranspose, Cropping1D, UpSampling1D, ZeroPadding1D, Reshape\n",
    "from keras.models import Sequential,Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from generator import Generator\n",
    "from keras import metrics\n",
    "import importlib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T16:26:30.590139Z",
     "start_time": "2024-11-02T16:26:17.623324Z"
    }
   },
   "id": "f70dabf5c8e7e463",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "from datasetLoader import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T16:26:30.653011Z",
     "start_time": "2024-11-02T16:26:30.611137Z"
    }
   },
   "id": "8d981596359c20a5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "def plot():\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss', marker=\".\")\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [MPG]')\n",
    "    plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T16:26:30.702013Z",
     "start_time": "2024-11-02T16:26:30.678010Z"
    }
   },
   "id": "d8275c36c94a1d86",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"data/initial kernels/Kernel_Silica_Adsorption.npy\", 'rb') as f:\n",
    "    data_sorb = np.load(f)\n",
    "    data_sorb_tensor = tf.constant((data_sorb.T[87:]).T)\n",
    "    data_sorb_tensor = tf.cast(data_sorb_tensor, tf.float32)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    pass\n",
    "    #print(\"data_sorb_tensor.shape = \", data_sorb_tensor.shape, y_pred[:,:128].shape)\n",
    "    isotherm_from_distribution = tf.tensordot(y_pred[:,:128], data_sorb_tensor, axes=1)\n",
    "    #print(\"isotherm_from_distribution = \", isotherm_from_distribution.shape, y_pred[:,128:].shape)\n",
    "    return 1*tf.reduce_sum(tf.square(y_pred[:,:128] - y_true[:,:128])) + 0.5*tf.reduce_sum(tf.square(y_pred[:,128:] - isotherm_from_distribution))\n",
    "\n",
    "# np.ediff1d(pore_widths, to_begin=pore_widths[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T16:26:34.147841Z",
     "start_time": "2024-11-02T16:26:32.192530Z"
    }
   },
   "id": "619b039f2d0a573a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model(x):\n",
    "    layer = []\n",
    "    layer.append(Input(shape=x[0].shape))\n",
    "    layer.append(Dense(200, activation='relu')(layer[-1]))\n",
    "    layer.append(Dense(200, activation='relu')(layer[-1]))\n",
    "    layer.append(Dense(200, activation='relu')(layer[-1]))\n",
    "    layer.append(Dense(200, activation='relu')(layer[-1]))\n",
    "    layer.append(Dense(128, activation='relu')(layer[-1]))\n",
    "    layer.append(Dense(128, activation='relu')(layer[-1]))\n",
    "    layer.append(Dense(128, activation='relu')(layer[-1]))\n",
    "    layer.append(Dense(128, activation='relu')(layer[-1]))\n",
    "    layer.append(Concatenate()([layer[-1], layer[0]]))\n",
    "    model = tf.keras.Model(inputs=layer[0], outputs=layer[-1])\n",
    "    model.compile(loss=custom_loss, optimizer='Adam')\n",
    "    #model.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "    return model\n",
    "\n",
    "def create_model_LSTM(x):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=64, input_shape=(371, 1), return_sequences=False, activation = \"elu\"))\n",
    "    #model.add(LSTM(units=64, activation = \"elu\"))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "    return model\n",
    "\n",
    "def create_model_CNN(x):\n",
    "    inputs = Input(shape=(371, 1), name=\"Input\")\n",
    "    c1 = Conv1D(filters=8, kernel_size=3, activation='relu', padding='same', name=\"c1\")(inputs)\n",
    "    p1 = MaxPooling1D(pool_size=2, padding='same', name=\"p1\")(c1)\n",
    "\n",
    "    c2 = Conv1D(filters=16, kernel_size=3, activation='relu', padding='same', name=\"c2\")(p1)\n",
    "    p2 = MaxPooling1D(pool_size=2, padding='same', name=\"p2\")(c2)\n",
    "    \n",
    "    c3 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', name=\"c3\")(p2)\n",
    "    p3 = MaxPooling1D(pool_size=2, padding='same', name=\"p3\")(c3)\n",
    "    \n",
    "    c4 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', name=\"c4\")(p3)\n",
    "    p4 = MaxPooling1D(pool_size=2, padding='same', name=\"p4\")(c4)\n",
    "    \n",
    "    c5 = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same', name=\"c5\")(p4)\n",
    "    p5 = MaxPooling1D(pool_size=2, padding='same', name=\"p5\")(c5)\n",
    "    \n",
    "    f1 = Flatten(name=\"f1\")(p5)\n",
    "    \n",
    "    d1 = Dense(128, activation='relu', name=\"d1\")(f1)\n",
    "    dp1 = Dropout(0.1)(d1)\n",
    "    d2 = Dense(128, activation='relu', name=\"d2\")(dp1)\n",
    "    dp2 = Dropout(0.1)(d2)\n",
    "    d3 = Dense(128, activation='relu', name=\"d3\")(dp2)\n",
    "    \n",
    "    input_for_loss = Reshape((371, ))(inputs)\n",
    "    outputs = Concatenate()([d3, input_for_loss])\n",
    "    \n",
    "    #outputs = d3\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs], name=\"CNN\")\n",
    "    #model.compile(loss='mean_squared_error', optimizer='Adam')\n",
    "    model.compile(loss=custom_loss, optimizer='Adam')\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T19:08:32.187788Z",
     "start_time": "2024-11-02T19:08:32.152787Z"
    }
   },
   "id": "8016a917c590c98a",
   "outputs": [],
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "source": [
    "# with open(\"data/datasets/reports_best_tyhanov.npz\", 'rb') as f:\n",
    "#     dataset = np.load(f)\n",
    "#     isotherm_data = dataset[\"isotherm_data\"]\n",
    "#     pore_distribution_data = dataset[\"pore_distribution_data\"]\n",
    "#     pore_widths = np.load(\"data/initial kernels/Size_Kernel_Silica_Adsorption.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "58dd8a7b2ff1a173",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#x, y = load_dataset('data/datasets/reports_best_tyhanov.npz')\n",
    "x, y = load_dataset('data/datasets/silica_random.npz')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T19:05:44.820455Z",
     "start_time": "2024-11-02T19:05:32.112698Z"
    }
   },
   "id": "a0d9a25ca1cb5c4b",
   "outputs": [],
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T19:05:45.127452Z",
     "start_time": "2024-11-02T19:05:44.878455Z"
    }
   },
   "id": "fffa14b27b9fcdc7",
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "source": [
    "with open(f'data/datasets/tyhanov_test.npz', \"wb\") as f:\n",
    "    np.savez_compressed(f, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T16:19:11.302378Z",
     "start_time": "2024-11-02T16:19:10.873075Z"
    }
   },
   "id": "6a25848952e39fe",
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "source": [
    "model = create_model_CNN(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T19:09:08.051777Z",
     "start_time": "2024-11-02T19:09:07.785485Z"
    }
   },
   "id": "a098bec7cbb731de",
   "outputs": [],
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 371, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " c1 (Conv1D)                    (None, 371, 8)       32          ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " p1 (MaxPooling1D)              (None, 186, 8)       0           ['c1[0][0]']                     \n",
      "                                                                                                  \n",
      " c2 (Conv1D)                    (None, 186, 16)      400         ['p1[0][0]']                     \n",
      "                                                                                                  \n",
      " p2 (MaxPooling1D)              (None, 93, 16)       0           ['c2[0][0]']                     \n",
      "                                                                                                  \n",
      " c3 (Conv1D)                    (None, 93, 32)       1568        ['p2[0][0]']                     \n",
      "                                                                                                  \n",
      " p3 (MaxPooling1D)              (None, 47, 32)       0           ['c3[0][0]']                     \n",
      "                                                                                                  \n",
      " c4 (Conv1D)                    (None, 47, 64)       6208        ['p3[0][0]']                     \n",
      "                                                                                                  \n",
      " p4 (MaxPooling1D)              (None, 24, 64)       0           ['c4[0][0]']                     \n",
      "                                                                                                  \n",
      " c5 (Conv1D)                    (None, 24, 128)      24704       ['p4[0][0]']                     \n",
      "                                                                                                  \n",
      " p5 (MaxPooling1D)              (None, 12, 128)      0           ['c5[0][0]']                     \n",
      "                                                                                                  \n",
      " f1 (Flatten)                   (None, 1536)         0           ['p5[0][0]']                     \n",
      "                                                                                                  \n",
      " d1 (Dense)                     (None, 128)          196736      ['f1[0][0]']                     \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 128)          0           ['d1[0][0]']                     \n",
      "                                                                                                  \n",
      " d2 (Dense)                     (None, 128)          16512       ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 128)          0           ['d2[0][0]']                     \n",
      "                                                                                                  \n",
      " d3 (Dense)                     (None, 128)          16512       ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 371)          0           ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 499)          0           ['d3[0][0]',                     \n",
      "                                                                  'reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 262,672\n",
      "Trainable params: 262,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T19:08:40.648426Z",
     "start_time": "2024-11-02T19:08:40.394428Z"
    }
   },
   "id": "27693f59c91f17da",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x000001EDEA2BE4A0> False\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001EDEA2BCD00> False\n",
      "<keras.layers.pooling.max_pooling1d.MaxPooling1D object at 0x000001EDEA2BEFE0> False\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001EDE98D3F40> False\n",
      "<keras.layers.pooling.max_pooling1d.MaxPooling1D object at 0x000001EDE98D2440> False\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001EDE9638730> False\n",
      "<keras.layers.pooling.max_pooling1d.MaxPooling1D object at 0x000001EDE96385E0> False\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001EE00075BD0> False\n",
      "<keras.layers.pooling.max_pooling1d.MaxPooling1D object at 0x000001EDEA2BD480> False\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001EE29C75030> False\n",
      "<keras.layers.pooling.max_pooling1d.MaxPooling1D object at 0x000001EE29C747F0> False\n",
      "<keras.layers.reshaping.flatten.Flatten object at 0x000001EE29C75F00> True\n",
      "<keras.layers.core.dense.Dense object at 0x000001EDEA2BD450> True\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x000001EE29D8A530> True\n",
      "<keras.layers.core.dense.Dense object at 0x000001EE29D8AA70> True\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x000001EE29D89990> False\n",
      "<keras.layers.core.dense.Dense object at 0x000001EE29D8BDF0> False\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "for i in range(11, 15):\n",
    "    model.layers[i].trainable = True\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T18:55:14.125382Z",
     "start_time": "2024-11-02T18:55:14.030386Z"
    }
   },
   "id": "8406040b54b028f9",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "source": [
    "from keras import backend as K\n",
    "K.set_value(model.optimizer.learning_rate, 0.001)\n",
    "mcp_save = tf.keras.callbacks.ModelCheckpoint(filepath='data/models/silica_CNN4_PINN.keras', save_best_only=True,\n",
    "                                              monitor='val_loss', mode='min', verbose=1, save_weights_only=False,\n",
    "                                              save_freq='epoch')\n",
    "\n",
    "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                                      patience=50, verbose=1, mode='auto')\n",
    "history = model.fit(np.array(x_train), np.array(y_train),\n",
    "                    epochs=50, batch_size=512, shuffle=True,\n",
    "                    validation_data=(np.array(x_train), np.array(y_train)), callbacks=[reduce_lr_loss, mcp_save])\n",
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T19:20:48.582551Z",
     "start_time": "2024-11-02T19:16:11.208719Z"
    }
   },
   "id": "191dc523763f2938",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 48.6693\n",
      "Epoch 1: val_loss improved from inf to 42.67891, saving model to data/models\\silica_CNN4_PINN.keras\n",
      "167/167 [==============================] - 88s 27ms/step - loss: 48.6693 - val_loss: 42.6789 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 47.8720\n",
      "Epoch 2: val_loss did not improve from 42.67891\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 47.8675 - val_loss: 48.2501 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 47.7449\n",
      "Epoch 3: val_loss improved from 42.67891 to 40.31203, saving model to data/models\\silica_CNN4_PINN.keras\n",
      "167/167 [==============================] - 5s 31ms/step - loss: 47.7462 - val_loss: 40.3120 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 47.5483\n",
      "Epoch 4: val_loss improved from 40.31203 to 36.19619, saving model to data/models\\silica_CNN4_PINN.keras\n",
      "167/167 [==============================] - 5s 31ms/step - loss: 47.5483 - val_loss: 36.1962 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 46.7010\n",
      "Epoch 5: val_loss did not improve from 36.19619\n",
      "167/167 [==============================] - 4s 26ms/step - loss: 46.6966 - val_loss: 40.9775 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 46.3840\n",
      "Epoch 6: val_loss did not improve from 36.19619\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 46.3733 - val_loss: 38.4815 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 46.4079\n",
      "Epoch 7: val_loss did not improve from 36.19619\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 46.4079 - val_loss: 44.4524 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 46.0965\n",
      "Epoch 8: val_loss did not improve from 36.19619\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 46.0730 - val_loss: 42.1196 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 45.7031\n",
      "Epoch 9: val_loss improved from 36.19619 to 35.51223, saving model to data/models\\silica_CNN4_PINN.keras\n",
      "167/167 [==============================] - 4s 25ms/step - loss: 45.6752 - val_loss: 35.5122 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 44.9879\n",
      "Epoch 10: val_loss did not improve from 35.51223\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 44.9879 - val_loss: 40.5400 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 44.8497\n",
      "Epoch 11: val_loss did not improve from 35.51223\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 44.8455 - val_loss: 36.2963 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 44.5487\n",
      "Epoch 12: val_loss did not improve from 35.51223\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 44.5317 - val_loss: 37.8127 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 44.7429\n",
      "Epoch 13: val_loss improved from 35.51223 to 34.52108, saving model to data/models\\silica_CNN4_PINN.keras\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 44.7429 - val_loss: 34.5211 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 43.7751\n",
      "Epoch 14: val_loss did not improve from 34.52108\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 43.7711 - val_loss: 40.5113 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 43.8827\n",
      "Epoch 15: val_loss did not improve from 34.52108\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 43.8876 - val_loss: 44.8185 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "163/167 [============================>.] - ETA: 0s - loss: 43.9603\n",
      "Epoch 16: val_loss did not improve from 34.52108\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 43.9248 - val_loss: 36.2689 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 43.1938\n",
      "Epoch 17: val_loss did not improve from 34.52108\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 43.1938 - val_loss: 42.1895 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 43.0747\n",
      "Epoch 18: val_loss did not improve from 34.52108\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 43.0747 - val_loss: 39.8933 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 43.2227\n",
      "Epoch 19: val_loss did not improve from 34.52108\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 43.2227 - val_loss: 37.9586 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 42.7060\n",
      "Epoch 20: val_loss did not improve from 34.52108\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 42.6969 - val_loss: 41.8139 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 42.3494\n",
      "Epoch 21: val_loss did not improve from 34.52108\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 42.3494 - val_loss: 36.0141 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 42.1729\n",
      "Epoch 22: val_loss did not improve from 34.52108\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 42.1690 - val_loss: 38.7784 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 42.1803\n",
      "Epoch 23: val_loss did not improve from 34.52108\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 42.1803 - val_loss: 39.2747 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 41.7997\n",
      "Epoch 24: val_loss improved from 34.52108 to 32.61765, saving model to data/models\\silica_CNN4_PINN.keras\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 41.7999 - val_loss: 32.6176 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 41.8791\n",
      "Epoch 25: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 41.8896 - val_loss: 38.1368 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 41.7179\n",
      "Epoch 26: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 4s 23ms/step - loss: 41.7156 - val_loss: 36.3759 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "163/167 [============================>.] - ETA: 0s - loss: 41.4556\n",
      "Epoch 27: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 41.4316 - val_loss: 35.4883 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 41.1155\n",
      "Epoch 28: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 41.1155 - val_loss: 40.6741 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 41.0286\n",
      "Epoch 29: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 41.0286 - val_loss: 43.9286 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 41.2573\n",
      "Epoch 30: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 41.2573 - val_loss: 39.4850 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 40.6580\n",
      "Epoch 31: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 40.6580 - val_loss: 42.8479 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "164/167 [============================>.] - ETA: 0s - loss: 41.0805\n",
      "Epoch 32: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 41.0928 - val_loss: 37.4533 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 40.5305\n",
      "Epoch 33: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 40.5267 - val_loss: 37.8763 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 40.3025\n",
      "Epoch 34: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 40.2988 - val_loss: 38.2773 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 40.2455\n",
      "Epoch 35: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 40.2418 - val_loss: 37.2614 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "163/167 [============================>.] - ETA: 0s - loss: 40.3428\n",
      "Epoch 36: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 40.3376 - val_loss: 37.2686 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "164/167 [============================>.] - ETA: 0s - loss: 40.1869\n",
      "Epoch 37: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 40.1821 - val_loss: 39.5869 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 39.8249\n",
      "Epoch 38: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.8249 - val_loss: 36.2861 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 39.9242\n",
      "Epoch 39: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.9267 - val_loss: 35.7187 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 39.8364\n",
      "Epoch 40: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.8327 - val_loss: 41.8750 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 39.8532\n",
      "Epoch 41: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.8568 - val_loss: 34.0222 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 39.7187\n",
      "Epoch 42: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.7187 - val_loss: 39.1563 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 39.7853\n",
      "Epoch 43: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.7817 - val_loss: 35.1781 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 39.6713\n",
      "Epoch 44: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.6676 - val_loss: 41.6744 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 39.7413\n",
      "Epoch 45: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.7413 - val_loss: 37.2257 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "166/167 [============================>.] - ETA: 0s - loss: 39.4689\n",
      "Epoch 46: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.4653 - val_loss: 35.9865 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "167/167 [==============================] - ETA: 0s - loss: 39.2851\n",
      "Epoch 47: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.2851 - val_loss: 39.4757 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 39.6964\n",
      "Epoch 48: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.6782 - val_loss: 43.8708 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "165/167 [============================>.] - ETA: 0s - loss: 39.3233\n",
      "Epoch 49: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.3241 - val_loss: 33.9749 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "163/167 [============================>.] - ETA: 0s - loss: 39.0375\n",
      "Epoch 50: val_loss did not improve from 32.61765\n",
      "167/167 [==============================] - 3s 20ms/step - loss: 39.0464 - val_loss: 38.7464 - lr: 0.0010\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T16:03:41.030461Z",
     "start_time": "2024-11-02T16:03:38.891147Z"
    }
   },
   "id": "5f88365122af1453",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "source": [
    "# load model\n",
    "model = tf.keras.models.load_model('data/models/silica_CNN4_PINN.keras', custom_objects={'abs': tf.math.abs, 'custom_loss': custom_loss})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T19:14:00.663697Z",
     "start_time": "2024-11-02T19:13:59.258569Z"
    }
   },
   "id": "c9a1a6a8cf9f8ba1",
   "outputs": [],
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#tf.keras.models.save_model(model,'data/models/silica_CNN3.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T18:38:16.754344Z",
     "start_time": "2024-11-02T18:38:16.630902Z"
    }
   },
   "id": "444075ca347a176b",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "source": [
    "# prediction = model.evaluate(np.array(x_test), np.array(y_test))\n",
    "prediction = model.predict(np.array(x_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T19:14:10.865893Z",
     "start_time": "2024-11-02T19:14:02.482279Z"
    }
   },
   "id": "d7c4e1ecdee1bcf7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 8s 10ms/step\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "source": [
    "# test on x_train\n",
    "def fetch_prediction(prediction):\n",
    "    return prediction[:128]\n",
    "\n",
    "pore_widths = np.load(\"data/initial kernels/Size_Kernel_Silica_Adsorption.npy\")\n",
    "pressures = np.load(\"data/initial kernels/Pressure_Silica.npy\")\n",
    "NX, NY = 3, 4\n",
    "figure, axis = plt.subplots(NX, NY)\n",
    "for i in range(NX):\n",
    "    for j in range(NY):\n",
    "        k = np.random.randint(0, len(x_test))\n",
    "        x_scale_factor = max(pore_widths) / len(x_test[k])\n",
    "        axis[i, j].plot(pore_widths / x_scale_factor, fetch_prediction(prediction[k]), marker=\".\", label=f\"Prediction\")\n",
    "        axis[i, j].plot(pore_widths / x_scale_factor, y_test[k], marker=\".\", label=\"Real distribution\")\n",
    "        axis[i, j].plot(pressures[77:-10]*500, x_test[k], label=\"Isotherm\")\n",
    "        kernal = (data_sorb.T[40:])\n",
    "        axis[i, j].plot(pressures[40:]*500, np.dot(kernal, prediction[k][:128]), label=\"New Isotherm\")\n",
    "        axis[i, j].set_title(f\"№ {k}\")\n",
    "        axis[i, j].title.set_size(10)\n",
    "plt.subplots_adjust(hspace=0.6, right=0.95, left=0.05, bottom=0.05, top=0.95)\n",
    "plt.legend()\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-11-02T19:14:28.720274Z",
     "start_time": "2024-11-02T19:14:12.969393Z"
    }
   },
   "id": "bbc48118bf79bc08",
   "outputs": [],
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test with test Generator\n",
    "from tools import TestApp\n",
    "\n",
    "gen = Generator(path_s=\"data/initial kernels/Kernel_Silica_Adsorption.npy\",\n",
    "                path_d=\"data/initial kernels/Kernel_Silica_Desorption.npy\",\n",
    "                path_p_d=\"data/initial kernels/Pressure_Silica.npy\",\n",
    "                path_p_s=\"data/initial kernels/Pressure_Silica.npy\",\n",
    "                path_a=\"data/initial kernels/Size_Kernel_Silica_Adsorption.npy\"\n",
    "                )\n",
    "# gen = Generator(path_s=\"data/initial kernels/Kernel_Carbon_Adsorption.npy\",\n",
    "#                               path_d=\"data/initial kernels/Kernel_Carbon_Desorption.npy\",\n",
    "#                               path_p_d=\"data/initial kernels/Pressure_Carbon.npy\",\n",
    "#                               path_p_s=\"data/initial kernels/Pressure_Carbon.npy\",\n",
    "#                               path_a=\"data/initial kernels/Size_Kernel_Carbon_Adsorption.npy\"\n",
    "#                             )\n",
    "\n",
    "#TestApp.App(model, gen)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "b25b4132001702fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp_file_list = [\"MCM-41\", \"SBA-15\", \"SBA-16\", \"MIL-101\", \"MIL-101_2\", \"DUT-49\", \"FDM-4\", \"PCN-333\", \"PCN-777\",\n",
    "                 \"MIL-100\"]\n",
    "\n",
    "p_exp_list = []\n",
    "n_s_exp_raw_list = []\n",
    "for exp_file_name in exp_file_list:\n",
    "    data = pd.read_csv(f\"data/real/{exp_file_name}.txt\", header=None)\n",
    "    # p_exp_list.append(data.iloc[:,1].to_numpy())\n",
    "    # n_s_exp_raw_list.append(data.iloc[:,3].to_numpy())\n",
    "    p_exp_list.append(data.iloc[:, 1].to_numpy())\n",
    "    n_s_exp_raw_list.append(data.iloc[:, 3].to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "d0179658dd4e6c12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "j = 2\n",
    "plt.plot(p_exp_list[j], n_s_exp_raw_list[j], marker=\".\", label=exp_file_list[j])\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "316deb7add602c0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# интерполируем экспериментальную изотерму под давления кернала\n",
    "n_s_exp_list = []\n",
    "for i in range(len(p_exp_list)):\n",
    "    n_s_exp_list.append(np.interp(gen.pressures_s[77:367], p_exp_list[i], n_s_exp_raw_list[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "bfb8c81559e024d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "j = 2\n",
    "plt.plot(gen.pressures_s[77:367], n_s_exp_list[j], marker=\".\", label=exp_file_list[j])\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "61ca6d25ee7153f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_s_exp_for_net_list = [pre_process_isotherm(np.copy(n_s_exp), scale=False) for n_s_exp in n_s_exp_list]\n",
    "fit_exp_list = [model.predict(np.array([n_s_exp_for_net])).T for n_s_exp_for_net in n_s_exp_for_net_list]\n",
    "fit_exp_list = [fetch_prediction(i) for i in fit_exp_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "964f2bfe8f0bb107"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NX, NY = 3, 4\n",
    "figure, axis = plt.subplots(NX, NY)\n",
    "k = 0\n",
    "for i in range(NX):\n",
    "    for j in range(NY):\n",
    "        x_scale_factor = max(gen.a_array) / max(p_exp_list[k])\n",
    "        y_scale_factor = max(fit_exp_list[k]) / max(n_s_exp_raw_list[k])\n",
    "        axis[i, j].plot(pore_widths, fit_exp_list[k], marker=\".\", label=f\"Distribution\")\n",
    "        axis[i, j].plot(p_exp_list[k] * x_scale_factor, n_s_exp_raw_list[k],\n",
    "                        label=f\"{exp_file_list[k]}\", marker=\".\")\n",
    "        \n",
    "        kernal = (data_sorb.T[40:])\n",
    "        axis[i, j].plot(gen.pressures_s[40:458]* x_scale_factor, np.dot(kernal, fit_exp_list[k]), label=\"Isotherm by distribution\")\n",
    "        \n",
    "        axis[i, j].set_title(f\"max at {round(gen.a_array[np.argmax(fit_exp_list[k])], 2)} nm\")\n",
    "        axis[i, j].title.set_size(12)\n",
    "        axis[i, j].legend(loc=\"upper right\")\n",
    "        axis[i, j].grid()\n",
    "        k += 1\n",
    "        if k >= len(fit_exp_list):\n",
    "            break\n",
    "plt.subplots_adjust(hspace=0.6, right=0.95, left=0.05, bottom=0.05, top=0.95)\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "dced44b8e1da2a3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Classic\n",
    "import inverse\n",
    "\n",
    "kernel = np.load(\"data/initial kernels/Kernel_Silica_Adsorption.npy\")\n",
    "\n",
    "### normalize on size\n",
    "# a_array = np.load(\"data/initial kernels/Size_Kernel_Silica_Adsorption.npy\")\n",
    "# for i in range(len(a_array)):\n",
    "#     kernel[i] /= a_array[i]\n",
    "#     kernel[i] /= a_array[i]\n",
    "###\n",
    "\n",
    "cut_kernel = []\n",
    "for i in range(len(kernel)):\n",
    "    cut_kernel.append(kernel[i][40:458])\n",
    "cut_kernel = np.array(cut_kernel)\n",
    "fit_classic_list = [inverse.fit_SLSQP(adsorption=n_s, kernel=cut_kernel, a_array=pore_widths) for n_s in n_s_exp_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "435b91d710c2ce9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "importlib.reload(inverse)\n",
    "\n",
    "\n",
    "def create_regularization_animation(file):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(10, 5, True)\n",
    "    fit_classic = inverse.fit_SLSQP(adsorption=n_s_exp_list[2], kernel=cut_kernel, a_array=pore_widths, alpha=0)\n",
    "    line1, = ax.plot(pore_widths[:-30], fit_classic.x[:-30], marker=\".\", label=f\"a = {0}\")\n",
    "\n",
    "    y_scale_factor = max(fit_classic.x) / max(fit_exp_list[2])\n",
    "    #plt.plot(pore_widths, fit_exp_list[2] * y_scale_factor, marker=\".\", label=f\"Суррогатная модель\")\n",
    "\n",
    "    ax.set_ylabel(\"Объем пор, $см^3$/ нм * г\")\n",
    "    ax.set_xlabel(\"Размер пор, нм\")\n",
    "\n",
    "    L = plt.legend(loc=1)  # Define legend objects\n",
    "\n",
    "    def update(frame):\n",
    "        a = frame / 4 + 2\n",
    "        fit_classic = inverse.fit_SLSQP(adsorption=n_s_exp_list[2], kernel=cut_kernel, a_array=pore_widths, alpha=a)\n",
    "        line1.set_ydata(fit_classic.x[:-30])\n",
    "        L.get_texts()[0].set_text(\n",
    "            f\"Распределение пор по размерам, параметр регуляризации α = {round(a-2,1)}\")  # Update label each at frame\n",
    "        return line1,\n",
    "\n",
    "    ani = animation.FuncAnimation(fig=fig, func=update, frames=100, interval=100)\n",
    "    writervideo = animation.FFMpegWriter(fps=30)\n",
    "    ani.save(file, writer=writervideo, dpi=200)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "create_regularization_animation(\"SBA-16_regularization.mp4\")\n",
    "def plot_regularization_graphs():\n",
    "    for a in [1, 5, 10, 50]:\n",
    "        fit_classic = inverse.fit_SLSQP(adsorption=n_s_exp_list[2], kernel=cut_kernel, a_array=pore_widths, alpha=a)\n",
    "        plt.plot(pore_widths, fit_classic.x, marker=\".\", label=f\"α = {a}\")\n",
    "    plt.ylabel(\"Объем пор, $см^3$/ нм * гр\")\n",
    "    plt.xlabel(\"Размер пор, нм\")\n",
    "    plot()\n",
    "#plot_regularization_graphs()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "1b0c708ab92c81f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NX, NY = 3, 4\n",
    "figure, axis = plt.subplots(NX, NY)\n",
    "k = 0\n",
    "for i in range(NX):\n",
    "    for j in range(NY):\n",
    "        x_scale_factor = max(gen.a_array) / max(p_exp_list[k])\n",
    "        y_scale_factor = max(fit_classic_list[k].x) / max(n_s_exp_raw_list[k])\n",
    "        y_scale_factor_net = max(fit_classic_list[k].x) / max(fit_exp_list[k])\n",
    "\n",
    "        axis[i, j].plot(pore_widths, fit_exp_list[k] * y_scale_factor_net, marker=\".\", label=f\"net\")\n",
    "        axis[i, j].plot(pore_widths, fit_classic_list[k].x, marker=\".\", label=f\"classic\")\n",
    "        axis[i, j].plot(p_exp_list[k] * x_scale_factor, n_s_exp_raw_list[k] * y_scale_factor,\n",
    "                        label=f\"{exp_file_list[k]}\", marker=\".\")\n",
    "        axis[i, j].set_title(f\"max at {round(gen.a_array[np.argmax(fit_classic_list[k].x)], 2)} nm\")\n",
    "        axis[i, j].title.set_size(12)\n",
    "        axis[i, j].legend(loc=\"upper right\")\n",
    "        axis[i, j].grid()\n",
    "        k += 1\n",
    "        if k >= len(fit_exp_list):\n",
    "            break\n",
    "plt.subplots_adjust(hspace=0.6, right=0.95, left=0.05, bottom=0.05, top=0.95)\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "aac060bb7ff7720e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Classic\n",
    "import inverse\n",
    "\n",
    "kernel = np.load(\"data/initial kernels/Kernel_Silica_Adsorption.npy\")\n",
    "\n",
    "### normalize on size\n",
    "# a_array = np.load(\"data/initial kernels/Size_Kernel_Silica_Adsorption.npy\")\n",
    "# for i in range(len(a_array)):\n",
    "#     kernel[i] /= a_array[i]\n",
    "#     kernel[i] /= a_array[i]\n",
    "###\n",
    "\n",
    "cut_kernel = []\n",
    "for i in range(len(kernel)):\n",
    "    cut_kernel.append(kernel[i][40:458])\n",
    "cut_kernel = np.array(cut_kernel)\n",
    "fit_classic_list = [inverse.fit_SLSQP(adsorption=n_s, kernel=cut_kernel, a_array=pore_widths) for n_s in n_s_exp_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "9949a77c1d2e89c0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "importlib.reload(inverse)\n",
    "\n",
    "\n",
    "def create_regularization_animation(file):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(10, 5, True)\n",
    "    fit_classic = inverse.fit_SLSQP(adsorption=n_s_exp_list[2], kernel=cut_kernel, a_array=pore_widths, alpha=0)\n",
    "    line1, = ax.plot(pore_widths[:-30], fit_classic.x[:-30], marker=\".\", label=f\"a = {0}\")\n",
    "\n",
    "    y_scale_factor = max(fit_classic.x) / max(fit_exp_list[2])\n",
    "    #plt.plot(pore_widths, fit_exp_list[2] * y_scale_factor, marker=\".\", label=f\"Суррогатная модель\")\n",
    "\n",
    "    ax.set_ylabel(\"Объем пор, $см^3$/ нм * г\")\n",
    "    ax.set_xlabel(\"Размер пор, нм\")\n",
    "\n",
    "    L = plt.legend(loc=1)  # Define legend objects\n",
    "\n",
    "    def update(frame):\n",
    "        a = frame / 4 + 2\n",
    "        fit_classic = inverse.fit_SLSQP(adsorption=n_s_exp_list[2], kernel=cut_kernel, a_array=pore_widths, alpha=a)\n",
    "        line1.set_ydata(fit_classic.x[:-30])\n",
    "        L.get_texts()[0].set_text(\n",
    "            f\"Распределение пор по размерам, параметр регуляризации α = {round(a-2,1)}\")  # Update label each at frame\n",
    "        return line1,\n",
    "\n",
    "    ani = animation.FuncAnimation(fig=fig, func=update, frames=100, interval=100)\n",
    "    writervideo = animation.FFMpegWriter(fps=30)\n",
    "    ani.save(file, writer=writervideo, dpi=200)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "create_regularization_animation(\"SBA-16_regularization.mp4\")\n",
    "def plot_regularization_graphs():\n",
    "    for a in [1, 5, 10, 50]:\n",
    "        fit_classic = inverse.fit_SLSQP(adsorption=n_s_exp_list[2], kernel=cut_kernel, a_array=pore_widths, alpha=a)\n",
    "        plt.plot(pore_widths, fit_classic.x, marker=\".\", label=f\"α = {a}\")\n",
    "    plt.ylabel(\"Объем пор, $см^3$/ нм * гр\")\n",
    "    plt.xlabel(\"Размер пор, нм\")\n",
    "    plot()\n",
    "#plot_regularization_graphs()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "ca3051b964f378a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NX, NY = 3, 4\n",
    "figure, axis = plt.subplots(NX, NY)\n",
    "k = 0\n",
    "for i in range(NX):\n",
    "    for j in range(NY):\n",
    "        x_scale_factor = max(gen.a_array) / max(p_exp_list[k])\n",
    "        y_scale_factor = max(fit_classic_list[k].x) / max(n_s_exp_raw_list[k])\n",
    "        y_scale_factor_net = max(fit_classic_list[k].x) / max(fit_exp_list[k])\n",
    "\n",
    "        axis[i, j].plot(pore_widths, fit_exp_list[k] * y_scale_factor_net, marker=\".\", label=f\"net\")\n",
    "        axis[i, j].plot(pore_widths, fit_classic_list[k].x, marker=\".\", label=f\"classic\")\n",
    "        axis[i, j].plot(p_exp_list[k] * x_scale_factor, n_s_exp_raw_list[k] * y_scale_factor,\n",
    "                        label=f\"{exp_file_list[k]}\", marker=\".\")\n",
    "        axis[i, j].set_title(f\"max at {round(gen.a_array[np.argmax(fit_classic_list[k].x)], 2)} nm\")\n",
    "        axis[i, j].title.set_size(12)\n",
    "        axis[i, j].legend(loc=\"upper right\")\n",
    "        axis[i, j].grid()\n",
    "        k += 1\n",
    "        if k >= len(fit_exp_list):\n",
    "            break\n",
    "plt.subplots_adjust(hspace=0.6, right=0.95, left=0.05, bottom=0.05, top=0.95)\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "707d030f7db4a23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compare net, classic, quantachrome distributions\n",
    "NX, NY = 3, 4\n",
    "figure, axis = plt.subplots(NX, NY)\n",
    "k = 0\n",
    "\n",
    "\n",
    "def calculate_isotherm_by_distribution(generator: Generator, a_array, distribution):\n",
    "    generator.a_array = a_array\n",
    "    generator.pore_distribution = distribution\n",
    "    generator.calculate_isotherms()\n",
    "    return generator.n_s\n",
    "\n",
    "\n",
    "#/np.ediff1d(pore_widths, to_begin=pore_widths[0])\n",
    "for i in range(NX):\n",
    "    for j in range(NY):\n",
    "        quantachrome_pore_size = \\\n",
    "            np.genfromtxt(f\"data/real/quantachrome/silica/distribution/{exp_file_list[k]}.csv\", delimiter=\",\")[1:].T[\n",
    "                0] / 10 * 2  # /10 - перевод в НМ * 2 - в QH размер - Half pore width.\n",
    "        quantachrome_dV = \\\n",
    "            np.genfromtxt(f\"data/real/quantachrome/silica/distribution/{exp_file_list[k]}.csv\", delimiter=\",\")[1:].T[3]\n",
    "        # isotherm_formQC = calculate_isotherm_by_distribution(gen, pore_widths, np.interp(pore_widths, quantachrome_pore_size, quantachrome_dV))\n",
    "        # y_scale_factor_QH = max(n_s_exp_raw_list[k]) / max(isotherm_formQC)\n",
    "        # quantachrome_dV *= y_scale_factor_QH\n",
    "\n",
    "        y_scale_factor_classic = max(quantachrome_dV) / max(fit_classic_list[k].x)\n",
    "        y_scale_factor_net = max(quantachrome_dV) / max(fit_exp_list[k])\n",
    "\n",
    "        axis[i, j].plot(pore_widths, fit_exp_list[k] * y_scale_factor_net, marker=\".\", label=f\"net\")\n",
    "        axis[i, j].plot(pore_widths, fit_classic_list[k].x * y_scale_factor_classic, marker=\".\", label=f\"classic\")\n",
    "        axis[i, j].plot(quantachrome_pore_size, quantachrome_dV, marker=\".\", label=f\"quantachrome\")\n",
    "        axis[i, j].set_title(f\"{exp_file_list[k]}\")\n",
    "        axis[i, j].title.set_size(12)\n",
    "        axis[i, j].legend(loc=\"upper right\")\n",
    "        axis[i, j].grid()\n",
    "        k += 1\n",
    "        if k >= len(fit_exp_list):\n",
    "            break\n",
    "plt.subplots_adjust(hspace=0.6, right=0.95, left=0.05, bottom=0.05, top=0.95)\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "8e0b9fbf987405b3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plots for presentation\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "plt = reload(plt)\n",
    "\n",
    "k = 0\n",
    "\n",
    "quantachrome_pore_size = \\\n",
    "    np.genfromtxt(f\"data/real/quantachrome/silica/distribution/{exp_file_list[k]}.csv\", delimiter=\",\")[1:].T[\n",
    "        0] / 10 * 2  # /10 - перевод в НМ * 2 - в QH размер - Half pore width.\n",
    "quantachrome_dV = \\\n",
    "    np.genfromtxt(f\"data/real/quantachrome/silica/distribution/{exp_file_list[k]}.csv\", delimiter=\",\")[1:].T[3]\n",
    "# isotherm_formQC = calculate_isotherm_by_distribution(gen, pore_widths, np.interp(pore_widths, quantachrome_pore_size, quantachrome_dV))\n",
    "# y_scale_factor_QH = max(n_s_exp_raw_list[k]) / max(isotherm_formQC)\n",
    "# quantachrome_dV *= y_scale_factor_QH\n",
    "\n",
    "y_scale_factor_classic = max(quantachrome_dV) / max(fit_classic_list[k].x)\n",
    "y_scale_factor_net = max(quantachrome_dV) / max(fit_exp_list[k])\n",
    "\n",
    "plt.plot(pore_widths, fit_exp_list[k] * y_scale_factor_net, marker=\".\", label=f\"Суррогатная модель\")\n",
    "plt.plot(pore_widths, fit_classic_list[k].x * y_scale_factor_classic, marker=\".\", label=f\"Математическое решение\")\n",
    "#plt.plot(quantachrome_pore_size, quantachrome_dV, marker=\".\", label=f\"Математическое решение QH\") \n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid()\n",
    "plt.title(f\"{exp_file_list[k]}\")\n",
    "\n",
    "# plt.xscale('log')\n",
    "plt.subplots_adjust(left=0.15,\n",
    "                    bottom=0.133,\n",
    "                    right=0.979,\n",
    "                    top=0.917,\n",
    "                    wspace=0.4,\n",
    "                    hspace=0.4)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"Объем пор, $см^3$/ нм * гр\")\n",
    "plt.xlabel(\"Размер пор, нм\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "c5e26ea811ae701c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plots for presentation 2\n",
    "k = 3\n",
    "plt.plot(p_exp_list[k], n_s_exp_raw_list[k], marker=\".\", color='b', label=f\"{exp_file_list[k]}\")\n",
    "k = 9\n",
    "plt.plot(p_exp_list[k], n_s_exp_raw_list[k], marker=\".\", color='r', label=f\"{exp_file_list[k]}\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid()\n",
    "plt.title(f\"Изотермы адсорбции\")\n",
    "\n",
    "# plt.xscale('log')\n",
    "plt.subplots_adjust(left=0.15,\n",
    "                    bottom=0.133,\n",
    "                    right=0.979,\n",
    "                    top=0.917,\n",
    "                    wspace=0.4,\n",
    "                    hspace=0.4)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"Адсорбция, $см^3$/г\")\n",
    "plt.xlabel(\"Давление, $P/P_{0}$\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "be93198745d6bc2d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plots for presentation 3\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6, 7))\n",
    "ax1.set_xlabel(\"Размер пор, нм\")\n",
    "ax1.set_ylabel(\"Объем пор, $см^3$/ нм * гр\")\n",
    "k = 0\n",
    "plt.title(f\"{exp_file_list[k]}\")\n",
    "quantachrome_pore_size = \\\n",
    "    np.genfromtxt(f\"data/real/quantachrome/silica/distribution/{exp_file_list[k]}.csv\", delimiter=\",\")[1:].T[\n",
    "        0] / 10 * 2  # /10 - перевод в НМ * 2 - в QH размер - Half pore width.\n",
    "quantachrome_dV = \\\n",
    "    np.genfromtxt(f\"data/real/quantachrome/silica/distribution/{exp_file_list[k]}.csv\", delimiter=\",\")[1:].T[3]\n",
    "# isotherm_formQC = calculate_isotherm_by_distribution(gen, pore_widths, np.interp(pore_widths, quantachrome_pore_size, quantachrome_dV))\n",
    "# y_scale_factor_QH = max(n_s_exp_raw_list[k]) / max(isotherm_formQC)\n",
    "# quantachrome_dV *= y_scale_factor_QH\n",
    "\n",
    "y_scale_factor_classic = max(quantachrome_dV) / max(fit_classic_list[k].x)\n",
    "y_scale_factor_net = max(quantachrome_dV) / max(fit_exp_list[k])\n",
    "\n",
    "ax1.plot(pore_widths[0:100], (fit_exp_list[k] * y_scale_factor_net)[0:100], marker=\".\", label=f\"Суррогатная модель\")\n",
    "ax1.plot(pore_widths[0:100], (fit_classic_list[k].x * y_scale_factor_classic)[0:100], marker=\".\",\n",
    "         label=f\"Математическое решение\")\n",
    "# ax1.tick_params(axis='y')\n",
    "# plt.legend(loc=\"right\")\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax3 = ax2.twiny()  # instantiate a second axes that shares the same x-axis\n",
    "ax3.set_xlabel(\"Давление, $P/P_{0}$\")\n",
    "ax2.set_ylabel(\"Адсорбция, $см^3$/г\")  # we already handled the x-label with ax1\n",
    "ax3.plot(p_exp_list[k], n_s_exp_raw_list[k], color='g', label=f\"Изотерма адсорбции\")\n",
    "# plt.legend(loc=\"right\")\n",
    "# \n",
    "# ax2.tick_params(axis='y')\n",
    "# plt.subplots_adjust(left=0.15,\n",
    "#                     bottom=0.133, \n",
    "#                     right=0.979, \n",
    "#                     top=0.917, \n",
    "#                     wspace=0.4, \n",
    "#                     hspace=0.4)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "2d0a60b839334253",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compare isotherms\n",
    "NX, NY = 2, 3\n",
    "figure, axis = plt.subplots(NX, NY)\n",
    "k = 0\n",
    "\n",
    "for i in range(NX):\n",
    "    for j in range(NY):\n",
    "        net_isotherm = calculate_isotherm_by_distribution(gen, pore_widths, fit_exp_list[k].T[0])\n",
    "        classic_isotherm = calculate_isotherm_by_distribution(gen, pore_widths, fit_classic_list[k].x)\n",
    "        quantachrome_data = np.genfromtxt(f\"data/real/quantachrome/silica/fitting/{exp_file_list[k]}.csv\",\n",
    "                                          delimiter=\",\")[1:].T\n",
    "        quantachrome_pore_size = \\\n",
    "            np.genfromtxt(f\"data/real/quantachrome/silica/distribution/{exp_file_list[k]}.csv\", delimiter=\",\")[1:].T[\n",
    "                0] / 10 * 2\n",
    "        quantachrome_dV = \\\n",
    "            np.genfromtxt(f\"data/real/quantachrome/silica/distribution/{exp_file_list[k]}.csv\", delimiter=\",\")[1:].T[3]\n",
    "        quantachrome_data2 = calculate_isotherm_by_distribution(gen, pore_widths,\n",
    "                                                                np.interp(pore_widths, quantachrome_pore_size,\n",
    "                                                                          quantachrome_dV))\n",
    "\n",
    "        y_scale_factor_net = max(net_isotherm) / max(n_s_exp_raw_list[k])\n",
    "        y_scale_factor_classic = max(classic_isotherm) / max(n_s_exp_raw_list[k])\n",
    "        y_scale_factor_quantachrome = max(quantachrome_data[1]) / max(n_s_exp_raw_list[k])\n",
    "        y_scale_factor_quantachrome2 = max(quantachrome_data2) / (\n",
    "            n_s_exp_raw_list[k][-1])  #max(quantachrome_data[1]) / max(n_s_exp_raw_list[k])\n",
    "        print(1 / y_scale_factor_quantachrome2)\n",
    "\n",
    "        axis[i, j].plot(p_exp_list[k], n_s_exp_raw_list[k], label=\"real\")\n",
    "        axis[i, j].plot(gen.pressures_s, classic_isotherm / y_scale_factor_classic, marker=\".\", label=f\"classic\")\n",
    "        axis[i, j].plot(gen.pressures_s, net_isotherm / y_scale_factor_net, label=\"net\")\n",
    "        # axis[i, j].plot(quantachrome_data[0], quantachrome_data[1]/y_scale_factor_quantachrome, label=\"quantachrome\")\n",
    "        # axis[i, j].plot(gen.pressures_s, quantachrome_data2/y_scale_factor_quantachrome2, label=\"quantachrome_from_kernal\")\n",
    "        axis[i, j].set_title(f\"{exp_file_list[k]}\")\n",
    "        axis[i, j].legend(loc=\"lower right\")\n",
    "        axis[i, j].grid()\n",
    "        k += 1\n",
    "        if k >= len(fit_exp_list):\n",
    "            break\n",
    "plt.subplots_adjust(hspace=0.6, right=0.95, left=0.05, bottom=0.05, top=0.95)\n",
    "plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "5e20fa504d7c45cc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#QUANTACHROME\n",
    "data = np.genfromtxt(\"data/real/quantachrome/silica/distribution/MIL-101.csv\", delimiter=\",\")[1:].T[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "a2947b6286fe73b7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "29ec7e76cb0598ac",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "5d7d844d6e720d14",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "40a95cf0ab8cc517",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
